# -*- coding: utf-8 -*-
"""Stage3.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1xwmb1Hs6VUW7C05tX713KGizNRVepjvP
"""

#import necessary packages
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt


from sklearn.preprocessing import StandardScaler
from sklearn.model_selection import train_test_split
from sklearn.model_selection import cross_val_score
from sklearn import metrics
from sklearn.metrics import accuracy_score
from sklearn import datasets, metrics, svm
from sklearn.svm import SVC
from sklearn.linear_model import Perceptron
from sklearn.linear_model import LogisticRegression
from sklearn.neighbors import KNeighborsClassifier
from sklearn import tree
from sklearn.tree import DecisionTreeClassifier
from sklearn.metrics import confusion_matrix
import seaborn as sns
import time
import warnings
warnings.filterwarnings('ignore')


#Version of sklearn: 1.2.2
#Versionn of pandas: 1.5.3

# from google.colab import drive
# drive.mount('/content/drive')

#Links to datasets
#Dataset Sources
#Online Shoppers Purchasing Intention Data Set
#https://archive.ics.uci.edu/dataset/468/online+shoppers+purchasing+intention+dataset
#Sales of Summer Clothes in E-commerce Wish
#https://www.kaggle.com/datasets/jmmvutu/summer-products-and-sales-in-ecommerce-wish/data?select=summer-products-with-rating-and-performance_2020-08.csv

def online_shopping():
  #import 'Online Shoppers Intention' dataset
  # online_shoppers_intention_df = pd.read_csv("/content/drive/MyDrive/CS519-Group Project/online_shoppers_intention.csv")
  online_shoppers_intention_df = pd.read_csv("online_shoppers_intention.csv")

  #Plot distributions of numerical variables
  numerical_vars = ['Administrative', 'Administrative_Duration', 'Informational', 'Informational_Duration',
                    'ProductRelated', 'ProductRelated_Duration', 'BounceRates', 'ExitRates', 'PageValues']
  online_shoppers_intention_df[numerical_vars].hist(bins=20, figsize=(15, 10))
  plt.suptitle('Distributions of Numerical Variables for Online Shopping Dataset')
  plt.show()

  # Plot count of categorical variables
  categorical_vars = ['Month', 'OperatingSystems', 'Browser', 'Region', 'TrafficType', 'VisitorType', 'Weekend', 'Revenue']
  fig, axes = plt.subplots(3, 3, figsize=(15, 10))
  axes = axes.ravel()
  for i, var in enumerate(categorical_vars):
      sns.countplot(x=var, data=online_shoppers_intention_df, ax=axes[i])
      axes[i].set_title(f'Count of {var}')
  plt.tight_layout()
  plt.show()

  # #show heading of 'Online Shoppers Intention' df
  # online_shoppers_intention_df.head()

  # #print count of each class 'REVENUE' in the dataset
  # print(online_shoppers_intention_df['Revenue'].value_counts())

  #TOTAL COUNT OF TRUE vs FALSE TRANSACTIONS OVER THE CALENDAR YEAR
  #group data by month and class
  month_count = online_shoppers_intention_df[['Month', 'Revenue']].copy()

  #filter true transactions
  month_count_true = month_count[(month_count['Revenue'] == True)]

  month_rev_true = (month_count_true['Month'].value_counts())
  month_rev_true = month_rev_true.reindex([ "Feb", "Mar", "May", "June", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"])
  month_rev_true.columns =['Month', 'True Count']

  #filter false transactions
  month_count_false = month_count[(month_count['Revenue'] == False)]

  month_rev_false = (month_count_false['Month'].value_counts())
  month_rev_false.columns = ['Month', 'False Count']
  month_rev_false = month_rev_false.reindex([ "Feb", "Mar", "May", "June", "Jul", "Aug", "Sep", "Oct", "Nov", "Dec"])

  #plot total number of true or false transactions over the calendar year
  month_rev_true.plot.line()
  month_rev_false.plot.line()
  plt.title('Sessions Over the Calendar Year')
  plt.ylabel('Number of Sessions')
  plt.xlabel('Month')
  plt.legend(['Positive', 'Negative'])
  plt.show()

  # Conversion Rate Analysis
  conversion_rates = online_shoppers_intention_df.groupby('VisitorType')['Revenue'].mean()
  print("Conversion Rates by Visitor Type:")
  print(conversion_rates)

  # Time Series Analysis
  monthly_revenue = online_shoppers_intention_df.groupby('Month')['Revenue'].mean()
  monthly_revenue.plot(kind='line', marker='o')
  plt.title('Monthly Revenue Trend for Online Shopping Dataset')
  plt.xlabel('Month')
  plt.ylabel('Mean Revenue')
  plt.grid(True)
  plt.show()

  # Calculate counts for each stage
  administrative_count = online_shoppers_intention_df['Administrative'].sum()
  informational_count = online_shoppers_intention_df['Informational'].sum()
  product_related_count = online_shoppers_intention_df['ProductRelated'].sum()

  # Plot funnel visualization
  plt.figure(figsize=(8, 4))
  plt.barh(['Administrative', 'Informational', 'Product Related'],
          [administrative_count, informational_count, product_related_count],
          color=['skyblue', 'salmon', 'lightgreen'])
  plt.xlabel('Number of Visitors')
  plt.title('Visitor Behavior Funnel for Online Shopping Dataset')
  plt.show()


  # Geographical Analysis
  revenue_by_region = online_shoppers_intention_df.groupby('Region')['Revenue'].sum()
  exit_rate_by_region = online_shoppers_intention_df.groupby('Region')['ExitRates'].sum()

  # Visualization
  plt.figure(figsize=(14, 10))

  # Browser Revenue
  plt.subplot(2, 2, 1)
  revenue_by_region.plot(kind='bar', color='skyblue')
  plt.xlabel('Region')
  plt.ylabel('Total Revenue')
  plt.title('Total Revenue by Region for Online Shopping Dataset')
  plt.xticks(rotation=45)

  # Browser Exit Rate
  plt.subplot(2, 2, 2)
  exit_rate_by_region.plot(kind='bar', color='salmon')
  plt.title('Total Exit by Region for Online Shopping Dataset')
  plt.xlabel('Region')
  plt.ylabel('Total Exit Rate')
  plt.xticks(rotation=45)

  plt.tight_layout()
  plt.show()

  #Browser Analysis
  browser_revenue = online_shoppers_intention_df.groupby('Browser')['Revenue'].mean()
  browser_exit_rate = online_shoppers_intention_df.groupby('Browser')['ExitRates'].mean()

  # Visualization
  plt.figure(figsize=(14, 10))

  # Browser Revenue
  plt.subplot(2, 2, 1)
  browser_revenue.plot(kind='bar', color='skyblue')
  plt.title('Mean Revenue by Browser for Online Shopping Dataset')
  plt.xlabel('Browser')
  plt.ylabel('Mean Revenue')
  plt.xticks(rotation=45)

  # Browser Exit Rate
  plt.subplot(2, 2, 2)
  browser_exit_rate.plot(kind='bar', color='salmon')
  plt.title('Mean Exit Rate by Browser for Online Shopping Dataset')
  plt.xlabel('Browser')
  plt.ylabel('Mean Exit Rate')
  plt.xticks(rotation=45)

  plt.tight_layout()
  plt.show()

  # Operating System Analysis
  os_revenue = online_shoppers_intention_df.groupby('OperatingSystems')['Revenue'].mean()
  os_exit_rate = online_shoppers_intention_df.groupby('OperatingSystems')['ExitRates'].mean()

  # Visualization
  plt.figure(figsize=(14, 10))

  # OS Revenue
  plt.subplot(2, 2, 1)
  os_revenue.plot(kind='bar', color='skyblue')
  plt.title('Mean Revenue by Operating System for Online Shopping Dataset')
  plt.xlabel('Operating System')
  plt.ylabel('Mean Revenue')

  # OS Exit Rate
  plt.subplot(2, 2, 2)
  os_exit_rate.plot(kind='bar', color='salmon')
  plt.title('Mean Exit Rate by Operating System for Online Shopping Dataset')
  plt.xlabel('Operating System')
  plt.ylabel('Mean Exit Rate')

  plt.tight_layout()
  plt.show()


  #create classification dataset (dropped some category data (strings), for quick analysis)
  # online_shoppers_intention_df = online_shoppers_intention_df.drop("Month", 1)
  # online_shoppers_intention_df = online_shoppers_intention_df.drop("VisitorType", 1)
  # online_shoppers_intention_df = online_shoppers_intention_df.drop("Weekend", 1)
  # X = online_shoppers_intention_df.drop("Revenue", 1)   #Feature Matrix
  # y = online_shoppers_intention_df["Revenue"]          #Target Variable
  
  online_shoppers_intention_df = online_shoppers_intention_df.drop(["Month", "VisitorType","Weekend"], axis=1)
  X = online_shoppers_intention_df.drop("Revenue", axis=1)   #Feature Matrix
  y = online_shoppers_intention_df["Revenue"]          #Target Variable


  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)

  #classifcation test - Perceptron


  #scale data
  sc = StandardScaler()
  sc.fit(X_train)
  X_train_std = sc.transform(X_train)
  X_test_std = sc.transform(X_test)

  st = time.time()
  #run model
  ppn = Perceptron(max_iter=40,eta0=0.1, random_state=1)
  ppn.fit(X_train_std, y_train)

  et = time.time()

  # get the execution time
  elapsed_time = et - st
  print('Execution time: %.2f'% elapsed_time, 'seconds')
  #calculate test accuracy
  y_pred = ppn.predict(X_test_std)
  print('Perceptron Test Accuracy for Revenue: %.2f' % accuracy_score(y_test, y_pred))

  #calculate training accuracy
  y_train_pred = ppn.predict(X_train)
  print("Perceptron Train Accuracy for Revenue: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

  #cross-fold score
  accuracy = cross_val_score(ppn, X, y, scoring='accuracy', cv = 10)
  print("CrossVal Mean for Revenue:",accuracy.mean())

  #calculate train accuracty
  # compute the confusion matrix
  cm = confusion_matrix(y_test,y_pred)

  #Plot the confusion matrix.
  sns.heatmap(cm,
              annot=True,
              fmt='g')
  plt.ylabel('Prediction',fontsize=13)
  plt.xlabel('Actual',fontsize=13)
  plt.title('Perceptron Confusion Matrix-Perceptron for Revenue',fontsize=17)
  plt.show()

  #classification test - Kernel SVM

  st = time.time()
  #run model
  svm = SVC(kernel='rbf', C=1.0, random_state=1, gamma=0.10)
  svm.fit(X_train_std, y_train)

  et = time.time()

  # get the execution time
  elapsed_time = et - st
  print('Execution time: %.2f'% elapsed_time, 'seconds')

  #calculate test accuracy
  y_pred = svm.predict(X_test_std)
  print('Non-Linear SVM (RBF Kernel) Test Accuracy for Revenue: %.2f' % accuracy_score(y_test, y_pred))

  #calculate training accuracy
  y_train_pred = svm.predict(X_train)
  print("Non-Linear SVM (RBF Kernel) Train Accuracy for Revenue: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

  #cross-fold score
  accuracy = cross_val_score(svm, X, y, scoring='accuracy', cv = 5)
  print("CrossVal Mean for Revenue:",accuracy.mean())

  # compute the confusion matrix
  cm = confusion_matrix(y_test,y_pred)

  #Plot the confusion matrix.
  sns.heatmap(cm,
              annot=True,
              fmt='g')
  plt.ylabel('Prediction',fontsize=13)
  plt.xlabel('Actual',fontsize=13)
  plt.title('Non-Linear SVM (RBF Kernel) Confusion Matrix-NonLinear(RBF) for Revenue',fontsize=17)
  plt.show()

  #classification test - Kneghbor
  st = time.time()
  #run model
  knn = KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski')
  knn.fit(X_train_std, y_train)

  et = time.time()

  # get the execution time
  elapsed_time = et - st
  print('Execution time: %.2f'% elapsed_time, 'seconds')

  #calculate test accuracy
  y_pred = knn.predict(X_test_std)
  print('K Nearest Neighbor Test Accuracy for Revenue: %.2f' % accuracy_score(y_test, y_pred))

  tree_model = DecisionTreeClassifier(criterion='gini', max_depth=10, random_state=1)
  tree_model.fit(X_train, y_train)
  #calculate training accuracy
  y_train_pred = tree_model.predict(X_train)
  print("K Nearest Neighbor Train Accuracy for Revenue: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

  #cross-fold score
  accuracy = cross_val_score(knn, X, y, scoring='accuracy', cv = 10)
  print("CrossVal Mean for Revenue:",accuracy.mean())

  # compute the confusion matrix
  cm = confusion_matrix(y_test, y_pred)

  #Plot the confusion matrix.
  sns.heatmap(cm,
              annot=True,
              fmt='g')
  plt.ylabel('Prediction',fontsize=13)
  plt.xlabel('Actual',fontsize=13)
  plt.title('K Nearest Neighbor Confusion Matrix-KNN for Revenue',fontsize=17)
  plt.show()

def summer_wish():
  #Import 'Sales of Summer Clothes in E-commerce Wish' dataset
  # df_summer_ratings = pd.read_csv('/content/drive/MyDrive/CS519-Group Project/summer_products/summer-products-with-rating-and-performance_2020-08.csv')
  df_summer_ratings = pd.read_csv('summer-products-with-rating-and-performance_2020-08.csv')

  numerical_vars = ['price', 'retail_price', 'rating', 'rating_count', 'merchant_rating_count', 'product_variation_inventory', 'merchant_rating']

  df_summer_ratings[numerical_vars].hist(bins=20, figsize=(15, 10))
  plt.suptitle('Distributions of Numerical Variables for Summer Products Rating and Performance Data')
  plt.show

  test = []
  test_label = []
  for index, row in df_summer_ratings.loc[:, ['units_sold']].iterrows():
      if row['units_sold'] < 100:
        # print('Bottom Tier: ' +  str(row['units_sold']))
        test.append(row['units_sold'])
        test_label.append('Bottom Tier')
      elif 5000 > row['units_sold'] > 100:
        # print('Mid Tier: ' +  str(row['units_sold']))
        test.append(row['units_sold'])
        test_label.append('Mid Tier')
      elif row['units_sold'] > 5000:
        # print('Top Tier: ' +  str(row['units_sold']))
        test.append(row['units_sold'])
        test_label.append('Top Tier')

  data_test = {'Units_Sold': test, 'Class': test_label}


  df_data_test = pd.DataFrame(data_test)
  df_unique = df_data_test['Class'].unique()


  for uniqueval in df_unique:
      y = df_data_test.Class.values
      y = np.where(y == uniqueval, -1, 1)
      X = df_data_test.Units_Sold.values
      X = X.reshape(-1, 1)

      X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=1, stratify=y)
      sc = StandardScaler()
      sc.fit(X_train)
      X_train_std = sc.transform(X_train)
      X_test_std = sc.transform(X_test)

      st = time.time()
      print(f'Perceptron Test for {uniqueval}')
      ppn = Perceptron(max_iter=40,eta0=0.1, random_state=1)
      ppn.fit(X_train_std, y_train)
      et = time.time()

      elapsed_time = et - st
      print('Execution time: %.2f'% elapsed_time, 'seconds')
      #calculate test accuracy
      y_pred = ppn.predict(X_test_std)
      print('Perceptron Test Accuracy: %.2f' % accuracy_score(y_test, y_pred))

      #calculate training accuracy
      y_train_pred = ppn.predict(X_train)
      print("Perceptron Train Accuracy: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

      #cross-fold score
      accuracy = cross_val_score(ppn, X, y, scoring='accuracy', cv = 10)
      print(f"CrossVal Mean for {uniqueval}:",round(accuracy.mean(),2))
      #calculate train accuracty
      # compute the confusion matrix
      cm = confusion_matrix(y_test,y_pred)

      #Plot the confusion matrix.
      sns.heatmap(cm,
                  annot=True,
                  fmt='g')
      plt.ylabel('Prediction',fontsize=13)
      plt.xlabel('Actual',fontsize=13)
      plt.title(f'Confusion Matrix-Perceptron {uniqueval}',fontsize=17)
      plt.show()

      #classification test - Kernel SVM
      print('*'*20)
      print(f'Kernel SVM Test for {uniqueval}')
      st = time.time()
      #run model
      svm = SVC(kernel='rbf', C=1.0, random_state=1, gamma=0.10)
      svm.fit(X_train, y_train)

      et = time.time()

      # get the execution time
      elapsed_time = et - st
      print('Execution time: %.2f'% elapsed_time, 'seconds')

      #calculate test accuracy
      y_pred = svm.predict(X_test)
      print(f'Non-Linear SVM (RBF Kernel) Test Accuracy for {uniqueval}: %.2f' % accuracy_score(y_test, y_pred))

      #calculate training accuracy
      y_train_pred = svm.predict(X_train)
      print(f"Non-Linear SVM (RBF Kernel) Train Accuracy for {uniqueval}: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

      #cross-fold score
      accuracy = cross_val_score(svm, X, y, scoring='accuracy', cv = 5)
      print(f"CrossVal Mean for {uniqueval}:",accuracy.mean())

      # compute the confusion matrix
      cm = confusion_matrix(y_test,y_pred)

      #Plot the confusion matrix.
      sns.heatmap(cm,
                  annot=True,
                  fmt='g')
      plt.ylabel('Prediction',fontsize=13)
      plt.xlabel('Actual',fontsize=13)
      plt.title(f'Confusion Matrix-NonLinear(RBF) for {uniqueval}',fontsize=17)
      plt.show()

      # #     #classification test - KNN
      print('*'*20)
      print(f'KNN Test for {uniqueval}')
      st = time.time()
      #run model
      knn = KNeighborsClassifier(n_neighbors=10, p=2, metric='minkowski')
      knn.fit(X_train, y_train)

      et = time.time()

      # get the execution time
      elapsed_time = et - st
      print('Execution time: %.2f'% elapsed_time, 'seconds')

      #calculate test accuracy
      y_pred = knn.predict(X_test)
      print(f'K Nearest Neighbor Test Accuracy for {uniqueval}: %.2f' % accuracy_score(y_test, y_pred))

      tree_model = DecisionTreeClassifier(criterion='gini', max_depth=10, random_state=1)
      tree_model.fit(X_train, y_train)
      #calculate training accuracy
      y_train_pred = tree_model.predict(X_train)
      print(f"K Nearest Neighbor Train Accuracy for {uniqueval}: %.2f" % metrics.accuracy_score(y_train, y_train_pred))

      #cross-fold score
      accuracy = cross_val_score(knn, X, y, scoring='accuracy', cv = 10)
      print(f"CrossVal Mean for {uniqueval}:",accuracy.mean())

      # compute the confusion matrix
      cm = confusion_matrix(y_test, y_pred)

      #Plot the confusion matrix.
      sns.heatmap(cm,
                  annot=True,
                  fmt='g')
      plt.ylabel('Prediction',fontsize=13)
      plt.xlabel('Actual',fontsize=13)
      plt.title(f'Confusion Matrix-KNN {uniqueval}',fontsize=17)
      plt.show()

      print('-'*20)

def main():
  online_shopping()
  summer_wish()

if __name__ == "__main__":
    main()